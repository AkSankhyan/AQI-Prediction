{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZFYfpzZbt2l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8cnOjp2buYQ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/AK/Downloads/Air-Quality-index-Prediction/Air-Quality-index-Prediction-main/Data/final_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pv03lDzkB4i"
   },
   "outputs": [],
   "source": [
    "#Splitting Data\n",
    "X = data.iloc[:, :-1] #Independent features\n",
    "y = data.iloc[:, -1] #Dependent feature\n",
    "\n",
    "#Train Test Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061/1061 [==============================] - 2s 2ms/step - loss: 24.3171 - mean_absolute_error: 24.3171 - val_loss: 23.8160 - val_mean_absolute_error: 23.8160\n",
      "Epoch 91/100\n",
      "1061/1061 [==============================] - 2s 1ms/step - loss: 24.5796 - mean_absolute_error: 24.5796 - val_loss: 23.8128 - val_mean_absolute_error: 23.8128\n",
      "Epoch 92/100\n",
      "1061/1061 [==============================] - 2s 2ms/step - loss: 23.7524 - mean_absolute_error: 23.7524 - val_loss: 24.3962 - val_mean_absolute_error: 24.3962\n",
      "Epoch 93/100\n",
      "1061/1061 [==============================] - 2s 1ms/step - loss: 23.6051 - mean_absolute_error: 23.6051 - val_loss: 24.5398 - val_mean_absolute_error: 24.5398\n",
      "Epoch 94/100\n",
      "1061/1061 [==============================] - 2s 2ms/step - loss: 23.8676 - mean_absolute_error: 23.8676 - val_loss: 24.1749 - val_mean_absolute_error: 24.1749\n",
      "Epoch 95/100\n",
      "1061/1061 [==============================] - 2s 1ms/step - loss: 24.0448 - mean_absolute_error: 24.0448 - val_loss: 23.9826 - val_mean_absolute_error: 23.9826\n",
      "Epoch 96/100\n",
      "1061/1061 [==============================] - 2s 2ms/step - loss: 23.5039 - mean_absolute_error: 23.5039 - val_loss: 24.6270 - val_mean_absolute_error: 24.6270\n",
      "Epoch 97/100\n",
      "1061/1061 [==============================] - 2s 2ms/step - loss: 22.8973 - mean_absolute_error: 22.8973 - val_loss: 24.0874 - val_mean_absolute_error: 24.0874\n",
      "Epoch 98/100\n",
      "1061/1061 [==============================] - 2s 1ms/step - loss: 23.5194 - mean_absolute_error: 23.5194 - val_loss: 24.5668 - val_mean_absolute_error: 24.5668\n",
      "Epoch 99/100\n",
      "1061/1061 [==============================] - 2s 1ms/step - loss: 23.5377 - mean_absolute_error: 23.5377 - val_loss: 24.8264 - val_mean_absolute_error: 24.8264\n",
      "Epoch 100/100\n",
      "1061/1061 [==============================] - 2s 2ms/step - loss: 23.3721 - mean_absolute_error: 23.3721 - val_loss: 23.9218 - val_mean_absolute_error: 23.9218\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history = NN_model.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = NN_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_test.values.reshape(-1,1)-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NN_model.predict([[38.82,26.56,0.82,10.25,20.06]]))\n",
    "print(NN_model.predict([[63.58,40.25,0.23,27.84,50.72]]))\n",
    "print(NN_model.predict([[62.33,2.60,0.59,7.46,29.58]]))\n",
    "print(NN_model.predict([[118.43,84.21,0.89,37.55,39.59]]))\n",
    "print(NN_model.predict([[37.67,37.32,1.06,7.06,34.92]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights:\n",
    "- ANN is also not giving more zccuracy than Random FOrest\n",
    "- AQI 421 is predicted as 279 which tells ANN is performing bad.\n",
    "- Thus we will use Random Forest as our primary model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AQI_Bucket.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (AQI Env)",
   "language": "python",
   "name": "aqi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
